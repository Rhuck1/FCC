{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d30aa66-26fd-41ee-b893-3a1542338105",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "from __future__ imports must occur at the beginning of the file (<ipython-input-1-40f72374355a>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-40f72374355a>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m from __future__ imports must occur at the beginning of the file\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolut_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66c2320c-89b6-44f2-8087-e1248591c945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c98525e3-4bd2-4358-92fd-183d534983e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669b1afd-1228-4cd5-9366-5b31a6f4562d",
   "metadata": {},
   "source": [
    "# CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f74ef5f-64a4-4785-8b97-f5838cd430ff",
   "metadata": {},
   "source": [
    "The sample program in this document builds and tests a model that classifies Iris flowers into three different species based on the size of their sepals and petals.\n",
    "\n",
    "You will train a model using the Iris data set. The Iris data set contains four features and one label. The four features identify the following botanical characteristics of individual Iris flowers:\n",
    "\n",
    "    sepal length\n",
    "    sepal width\n",
    "    petal length\n",
    "    petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf05bfd1-9a15-4384-9a92-535e6b05838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "904cd65f-c69b-4853-b666-274f6e32bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f66dccf9-a8cc-4f1a-9a72-f06991500062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa5ef494-62eb-4315-a17e-b0609dfb65c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "train.head() # Now species column is gone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "230d6473-67b3-4e09-bc6e-8ec631a2ec5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2e51b2-c85b-42f7-913f-0489a67fcce9",
   "metadata": {},
   "source": [
    "### Create input function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f42bc0-7072-44ca-9b2c-019fb6b49036",
   "metadata": {},
   "source": [
    "You must create input functions to supply data for training, evaluating, and prediction.\n",
    "\n",
    "An input function is a function that returns a tf.data.Dataset object which outputs the following two-element tuple:\n",
    "\n",
    "    features - A Python dictionary in which:\n",
    "        Each key is the name of a feature.\n",
    "        Each value is an array containing all of that feature's values.  \n",
    "    label - An array containing the values of the label for every example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cdb982e-8206-4ffe-a23e-ab9247366481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to demonstrate the format of the input function, here's a simple implementation:\n",
    "def input_evaluation_set():\n",
    "    features = {'SepalLength': np.array([6.4, 5.0]),\n",
    "                'SepalWidth':  np.array([2.8, 2.3]),\n",
    "                'PetalLength': np.array([5.6, 3.3]),\n",
    "                'PetalWidth':  np.array([2.2, 1.0])}\n",
    "    labels = np.array([2, 1])\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f5bc41b-e188-4b73-b456-08b9e60a15de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    \"\"\"An input function for training or evaluating\"\"\"\n",
    "    # Convert the inputs to a Dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    \n",
    "    # Shuffle and repeat if you are in training mode\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "        \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5975e0-9ea8-4cda-8270-ab5cb6f17fc0",
   "metadata": {},
   "source": [
    "### Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1660c5c-8e10-496f-88e6-a1a8bf805cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78595e48-5a0a-49e4-b42d-691bc0875e13",
   "metadata": {},
   "source": [
    "### Instantiate an estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acbe6ef-6afa-4d4e-a987-46cb61ddb4c6",
   "metadata": {},
   "source": [
    "The Iris problem is a classic classification problem. Fortunately, TensorFlow provides several pre-made classifier Estimators, including:\n",
    "\n",
    "    tf.estimator.DNNClassifier for deep models that perform multi-class classification.\n",
    "    tf.estimator.DNNLinearCombinedClassifier for wide & deep models.\n",
    "    tf.estimator.LinearClassifier for classifiers based on linear models.\n",
    "\n",
    "For the Iris problem, tf.estimator.DNNClassifier seems like the best choice. Here's how you instantiated this Estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "106fab5a-31ae-491d-b394-1bd0a7c2b909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_103cg_3\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp_103cg_3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively\n",
    "    hidden_units=[30,10],\n",
    "    # The model must choose between 3 classes\n",
    "    n_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b5f5fc-12a0-4d77-b5f9-3da4e9ac9bd6",
   "metadata": {},
   "source": [
    "Now that you have an Estimator object, you can call methods to do the following:\n",
    "\n",
    "    Train the model.\n",
    "    Evaluate the trained model.\n",
    "    Use the trained model to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1177d211-36f8-4af0-a0dd-73476fcfc564",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "853a636e-3609-4ba6-bfc5-2fc6e852e9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bobbyhuck/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/bobbyhuck/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/adagrad.py:88: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp_103cg_3/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.7569747, step = 0\n",
      "INFO:tensorflow:global_step/sec: 531.957\n",
      "INFO:tensorflow:loss = 1.1364969, step = 100 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.633\n",
      "INFO:tensorflow:loss = 1.0465331, step = 200 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 681.486\n",
      "INFO:tensorflow:loss = 1.0055767, step = 300 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 718.797\n",
      "INFO:tensorflow:loss = 0.9725034, step = 400 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 569.422\n",
      "INFO:tensorflow:loss = 0.90958846, step = 500 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 633.056\n",
      "INFO:tensorflow:loss = 0.8609165, step = 600 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 659.624\n",
      "INFO:tensorflow:loss = 0.82532525, step = 700 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 543.14\n",
      "INFO:tensorflow:loss = 0.7935305, step = 800 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.775\n",
      "INFO:tensorflow:loss = 0.78059566, step = 900 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 539.466\n",
      "INFO:tensorflow:loss = 0.7759623, step = 1000 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 635.78\n",
      "INFO:tensorflow:loss = 0.74846256, step = 1100 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.313\n",
      "INFO:tensorflow:loss = 0.729766, step = 1200 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 659.479\n",
      "INFO:tensorflow:loss = 0.7219599, step = 1300 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.827\n",
      "INFO:tensorflow:loss = 0.69419456, step = 1400 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.798\n",
      "INFO:tensorflow:loss = 0.6938069, step = 1500 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.891\n",
      "INFO:tensorflow:loss = 0.6836151, step = 1600 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.952\n",
      "INFO:tensorflow:loss = 0.6662421, step = 1700 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.703\n",
      "INFO:tensorflow:loss = 0.66609347, step = 1800 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.223\n",
      "INFO:tensorflow:loss = 0.6631745, step = 1900 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 659.053\n",
      "INFO:tensorflow:loss = 0.65347314, step = 2000 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.912\n",
      "INFO:tensorflow:loss = 0.63269204, step = 2100 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.324\n",
      "INFO:tensorflow:loss = 0.63006204, step = 2200 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.926\n",
      "INFO:tensorflow:loss = 0.6140977, step = 2300 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.574\n",
      "INFO:tensorflow:loss = 0.61519086, step = 2400 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 721.7\n",
      "INFO:tensorflow:loss = 0.61113733, step = 2500 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 700.342\n",
      "INFO:tensorflow:loss = 0.6066735, step = 2600 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.402\n",
      "INFO:tensorflow:loss = 0.5987401, step = 2700 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 705.95\n",
      "INFO:tensorflow:loss = 0.59101707, step = 2800 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.508\n",
      "INFO:tensorflow:loss = 0.58155733, step = 2900 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 573.297\n",
      "INFO:tensorflow:loss = 0.58463097, step = 3000 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.089\n",
      "INFO:tensorflow:loss = 0.56774306, step = 3100 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 681.017\n",
      "INFO:tensorflow:loss = 0.55825937, step = 3200 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 702.699\n",
      "INFO:tensorflow:loss = 0.55383086, step = 3300 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.112\n",
      "INFO:tensorflow:loss = 0.5537837, step = 3400 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 637.101\n",
      "INFO:tensorflow:loss = 0.5351032, step = 3500 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.281\n",
      "INFO:tensorflow:loss = 0.5404603, step = 3600 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.368\n",
      "INFO:tensorflow:loss = 0.53461576, step = 3700 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 725.893\n",
      "INFO:tensorflow:loss = 0.52232623, step = 3800 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.01\n",
      "INFO:tensorflow:loss = 0.5247184, step = 3900 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.032\n",
      "INFO:tensorflow:loss = 0.5275763, step = 4000 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 692.069\n",
      "INFO:tensorflow:loss = 0.51876944, step = 4100 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.431\n",
      "INFO:tensorflow:loss = 0.5172024, step = 4200 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.532\n",
      "INFO:tensorflow:loss = 0.5071369, step = 4300 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.644\n",
      "INFO:tensorflow:loss = 0.5001087, step = 4400 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.194\n",
      "INFO:tensorflow:loss = 0.49641576, step = 4500 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.996\n",
      "INFO:tensorflow:loss = 0.50213057, step = 4600 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.225\n",
      "INFO:tensorflow:loss = 0.48506632, step = 4700 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.075\n",
      "INFO:tensorflow:loss = 0.48877114, step = 4800 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 642.058\n",
      "INFO:tensorflow:loss = 0.4661392, step = 4900 (0.156 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmp_103cg_3/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.48615345.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7ff2b4be8690>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementing lambda function because our input function does not return\n",
    "# another function like the linear regression input function did\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f72de7-e264-44a3-9dca-021881fe389a",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4777aa7-b1c9-4ad0-858f-e69d94f220b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-08-27T12:29:52\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp_103cg_3/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.15222s\n",
      "INFO:tensorflow:Finished evaluation at 2023-08-27-12:29:52\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.8333333, average_loss = 0.5488819, global_step = 5000, loss = 0.5488819\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmp_103cg_3/model.ckpt-5000\n",
      "\n",
      "Test set accuracy: 0.833\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f458380b-8541-4f9c-8a2f-9d50a5f659e2",
   "metadata": {},
   "source": [
    "### Predictions (inferring) from the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8bd5b3-a55c-4367-b277-40fbec62d4e1",
   "metadata": {},
   "source": [
    "You now have a trained model that produces good evaluation results. You can now use the trained model to predict the species of an Iris flower based on some unlabeled measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c4048fa-0fe5-4798-836f-b1cec82fbfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type numeric values when prompted\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "SepalLength:  2.4\n",
      "SepalWidth:  2.6\n",
      "PetalLength:  6.5\n",
      "PetalWidth:  6.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp_103cg_3/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Virginica\" (90.884149%)\n"
     ]
    }
   ],
   "source": [
    "def input_fn(features, batch_size=256):\n",
    "    \"\"\"An input function for prediction.\"\"\"\n",
    "    # Convert the inputs to a Dataset without labels\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "predict = {}\n",
    "\n",
    "print(\"Please type numeric values when prompted\")\n",
    "\n",
    "for feature in features:\n",
    "    \n",
    "    valid = True\n",
    "    \n",
    "    while valid:        \n",
    "        val = input(feature + \": \")\n",
    "        \n",
    "        if not val.isdigit():\n",
    "            valid = False\n",
    "            \n",
    "    predict[feature] = [float(val)]\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda: input_fn(predict))\n",
    "\n",
    "for pred_dict in predictions:\n",
    "    \n",
    "    print(pred_dict) # To understand what class_ids references, which is the position of the most probable species name in the SPECIES array (list) above\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "    \n",
    "    print('Prediction is \"{}\" ({:1f}%)'.format(\n",
    "        SPECIES[class_id], 100 * probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cf20d3-8130-428c-bb4f-69820732c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbf07835-c51d-4ae8-82c5-93c3f2b5bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from the model\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "def input_fn(features, batch_size=256):\n",
    "    \"\"\"An input function for prediction.\"\"\"\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda: input_fn(predict_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "225a1372-8a4e-43a5-9dc8-4e48bbf303fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp_103cg_3/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Setosa\" (73.0%), expected \"Setosa\"\n",
      "Prediction is \"Versicolor\" (47.1%), expected \"Versicolor\"\n",
      "Prediction is \"Virginica\" (60.0%), expected \"Virginica\"\n"
     ]
    }
   ],
   "source": [
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\n",
    "        SPECIES[class_id], 100 * probability, expec))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
